{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Given that our stakeholders are seeking to understand what factors drive the price of a used car then their goal is to improve their sales and meet market demand. They have provided as a dataset of used car sales and have asked us to determine which factors make a car more or less expensive. A recent [report](https://www.statista.com/statistics/183713/value-of-us-passenger-cas-sales-and-leases-since-1990/) shows that used car sales doubles the amount of new car sales. The used car market is lucrative with high demand from consumers. Our stakeholder wants to stay ahead of the curve and understanding their customer's preferences can help lead to more sales. Used car dealerships also have to acquire cars for inventory from other entities. If our stakeholder can reasonably determine the cost of a used vehicle they can better understand their margins and when to purchase a vehicle for inventory. It is also important to understand what customers value in used cars. Knowing what drives a consumer to purchase a used vehicle can help our stakeholders avoid costly mistakes when acquiring inventory."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "vehicles_df = pd.read_csv('data/vehicles.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# First we should get the basic facts of the data (describe, info, null checks, duplicate checks)\n",
    "vehicles_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The id and VIN column are not important for analysis so we will definitely remove them."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "vehicles_df.describe()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "vehicles_df.describe(include='object')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'Row count: {vehicles_df.shape[0]}, Duplicate count: {vehicles_df.shape[0] - vehicles_df.drop_duplicates().shape[0]}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "vehicles_df.isna().mean().round(2)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Luckily, we do not have duplicates. However, we are missing values, specifically the condition and cylinders attributes are missing in over 40% of rows. Color is missing in 31% of rows. Size is missing in 72% of rows. Drive is missing in 31% of rows. I know that these attributes are important in determining the price of a car from prior analysis. The amount of missing data is concerning and the best course of action may be to impute them. That may mislead our model and we should be wary of that. However, dropping over 40% of the data isn't something we should do. One way to impute this data would be to find a finding an identical year and model then we would select the most seen value for that respective column; we can leverage scipy's `SimpleImputer`. This can help us deduce the missing attributes.\n",
    "\n",
    "I will create an imputed dataset and run my analysis on both of them."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predefine to avoid extra computation\n",
    "groupby_model_year = vehicles_df.groupby(['model', 'year'])\n",
    "# This somewhat mimics SimpleImputer. If we wanted to get fancy we would use KNN and leverage sales price in imputation\n",
    "def impute_field_by_model_year(row, field_to_update):\n",
    "    # ensure fields are not na and some non na value exists\n",
    "    try:\n",
    "        # take the most common occurrences for model and year\n",
    "        group = groupby_model_year.get_group((row['model'], row['year']))\n",
    "        non_na_values = group[field_to_update].dropna()\n",
    "        if not non_na_values.empty:\n",
    "            return non_na_values.mode().iloc[0]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# copy vehicles df and impute columns missing values\n",
    "imputed_vehicle_df = vehicles_df.copy(deep=True)\n",
    "fields_to_impute = ['condition', 'cylinders', 'drive', 'size', 'type', 'paint_color']\n",
    "for field in fields_to_impute:\n",
    "    na_filter = imputed_vehicle_df[field].isna()\n",
    "    imputed_vehicle_df.loc[na_filter, field] = imputed_vehicle_df[na_filter].apply(lambda row: impute_field_by_model_year(row, field), axis=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "imputed_vehicle_df.isna().mean().round(2)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The imputed vehicle dataframe is looking a lot better.\n",
    "<table>\n",
    "<tr>\n",
    "<th>column</th>\n",
    "<th>old missing value percent</th>\n",
    "<th>new missing value percent</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>condition</td>\n",
    "<td>0.41</td>\n",
    "<td>0.09</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>condition</td>\n",
    "<td>0.42</td>\n",
    "<td>0.14</td>\n",
    "</tr>\n",
    "<td>drive</td>\n",
    "<td>0.31</td>\n",
    "<td>0.10</td>\n",
    "</tr>\n",
    "</tr>\n",
    "<td>size</td>\n",
    "<td>0.72</td>\n",
    "<td>0.30</td>\n",
    "</tr>\n",
    "</tr>\n",
    "<td>type</td>\n",
    "<td>0.22</td>\n",
    "<td>0.05</td>\n",
    "</tr>\n",
    "</tr>\n",
    "<td>paint_color</td>\n",
    "<td>0.31</td>\n",
    "<td>0.08</td>\n",
    "</tr>\n",
    "</table?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start by checking a histogram of sales prices"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.box(vehicles_df, x='price', title='Price attribute has unrealistic values',\n",
    "                   labels={'price': 'Price', 'count': 'Count'})\n",
    "fig.show()\n",
    "fig.write_image('images/box_amount.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above is not realistic. We are seeing vehicles selling for billions. I will remove outliers using iqr."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q1 = vehicles_df['price'].quantile(0.25)\n",
    "q3 = vehicles_df['price'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "vehicles_df_no_outlier = vehicles_df.query(f'price >= {lower_bound} and price <= {upper_bound}')\n",
    "imputed_vehicle_df = imputed_vehicle_df.query(f'price >= {lower_bound} and price <= {upper_bound}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.box(vehicles_df_no_outlier, x='price', title='Majority of vehicles fall between &#36;5,799 - &#36;25,590',\n",
    "                   labels={'price': 'Price', 'count': 'Count'})\n",
    "fig.show()\n",
    "fig.write_image('images/box_amount_outliers.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
